{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ljRApNerjGld"
   },
   "outputs": [],
   "source": [
    "!pip install wandb -U -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A3w3SAJwaeyS"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import wandb\n",
    "import gensim\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from torchtext.vocab import vocab\n",
    "import multiprocessing\n",
    "import gc\n",
    "from gensim.models import KeyedVectors\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, OneCycleLR, StepLR\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1651383509480,
     "user": {
      "displayName": "Vikash Kumar",
      "userId": "09277849211533188513"
     },
     "user_tz": 300
    },
    "id": "L-OQLaW6wfNI",
    "outputId": "ce46631f-906b-4b38-bdc9-21e5a7cd0a30"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 566,
     "status": "ok",
     "timestamp": 1651383510043,
     "user": {
      "displayName": "Vikash Kumar",
      "userId": "09277849211533188513"
     },
     "user_tz": 300
    },
    "id": "ciRj4Uz8cnND",
    "outputId": "49fd33fb-8b1c-4c81-da17-bf0f0f8e80ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZOvpWOHfco5D"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/content/drive/MyDrive/Custom_Functions/\")\n",
    "import custom_functions as cf\n",
    "import custom_preprocessor as cp\n",
    "import plot_learning_curve as plc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-DJgtvD3cuLT"
   },
   "outputs": [],
   "source": [
    "data_path = Path(\"/content/drive/MyDrive/Datasets_Models/Datasets/\")\n",
    "model_path = Path(\"/content/drive/MyDrive/Datasets_Models/Models/\")\n",
    "embedding_path = Path(\"/content/drive/MyDrive/Datasets_Models/Word_Embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FoWoKEs3c5LL"
   },
   "outputs": [],
   "source": [
    "X_cleaned_comp = data_path/\"df_stackoverflow_multilabel_X_cleaned.joblib\"\n",
    "y_cleaned_comp = data_path/\"df_stackoverflow_multilabel_y_cleaned.joblib\"\n",
    "X = joblib.load(X_cleaned_comp)\n",
    "y = joblib.load(y_cleaned_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1651383513451,
     "user": {
      "displayName": "Vikash Kumar",
      "userId": "09277849211533188513"
     },
     "user_tz": 300
    },
    "id": "407CGhHDdA6V",
    "outputId": "22cf6c64-2b1c-40a8-fa10-ff53d5487d06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['asp query string dropdowni webpage follow control relevance    dropdownlist value hyperlink redirect page call   page cancel button redirect user menu page like user click hyperlink edit page index dropdownlist preserve query string page follow aspx code sure proceed < asp hyperlink      id=\"lnkedit      navigateurl=\\'<% + eval(\"userid + sure > < /asp hyperlink >   < asp dropdownlist      id=\"mydropdown      < asp listitems/ > < /asp dropdownlist >   edit clarify m navigateurl query string eval determine user id', 'run javascript code server java code?i want run javascript code server want manipulate result return javascript inside java code', 'linq sql throw exception row find changedhi linq sql get error row find change update table help linq query show error unable figure problem work get permanent solution fix problem twtmob_campainincomedetails_tb incomedetail = datacontext.twtmob_campainincomedetails_tb single(twtincome = > = = tempincome                  decimal temppayout = decimal parse(lblpertweet text                  decimal temptotal = temppayout + tempmoneyearne                  = convert tostring(temptotal                  = temptweet + 1                  = lblbonus text                  = tempbudurl                  datacontext submitchange    twtmob_user_tb twtuserdetail = datacontext.twtmob_user_tbs single(twtdetail = > = = tempuserid                       float temppayout = float parse(lblpertweet text              float tempoutstandingtotal = temppayout+tempoutstanding              = tempoutstandingtotal              datacontext submitchange           ']\n",
      "[['0', '9'], ['1', '3'], ['0', '9']]\n"
     ]
    }
   ],
   "source": [
    "print(X[0:3])\n",
    "print(y[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GW7eu05XdDUs"
   },
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 107,
     "status": "ok",
     "timestamp": 1651383513686,
     "user": {
      "displayName": "Vikash Kumar",
      "userId": "09277849211533188513"
     },
     "user_tz": 300
    },
    "id": "FTV9-jwJdMka",
    "outputId": "10f8efa5-a577-4f29-dca7-ab629faf0465"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: 28456, X_valid: 9485, X_test: 9486, y_train: 28456, y_valid: 9485, y_test: 9486\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, X_test, y_train, y_valid, y_test = cf.train_valid_test_split(X, y, 0.6, 0.2, 0.2, stratify=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 811,
     "status": "ok",
     "timestamp": 1651383514496,
     "user": {
      "displayName": "Vikash Kumar",
      "userId": "09277849211533188513"
     },
     "user_tz": 300
    },
    "id": "Uwj3qMePdPjV",
    "outputId": "e41127e6-3483-4c8f-bf94-1b4af991ac8a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvikashk\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 108,
     "status": "ok",
     "timestamp": 1651383514601,
     "user": {
      "displayName": "Vikash Kumar",
      "userId": "09277849211533188513"
     },
     "user_tz": 300
    },
    "id": "eN_rQ5qIjDAg",
    "outputId": "d214b535-59b2-4a52-a084-3f6ca382f343"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: 28456, X_valid: 9485, X_test: 9486, y_train: 28456, y_valid: 9485, y_test: 9486\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, X_test, y_train, y_valid, y_test = cf.train_valid_test_split(X, y, 0.6, 0.2, 0.2, stratify=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aBAq80tEkW9-"
   },
   "outputs": [],
   "source": [
    "X_train_subset1, y_train_subset1, X_valid_subset1, y_valid_subset1 = X_train[:100], y_train[:100], X_valid[:100], y_valid[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "foiP7zReklRt"
   },
   "outputs": [],
   "source": [
    "X_gensim_cleaned = list(map(gensim.utils.simple_preprocess, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7EohJNaBks8J"
   },
   "outputs": [],
   "source": [
    "X_gensim_cleaned_X = []\n",
    "for lst in X_gensim_cleaned:\n",
    "    X_gensim_cleaned_X.append(\" \".join(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1651383525689,
     "user": {
      "displayName": "Vikash Kumar",
      "userId": "09277849211533188513"
     },
     "user_tz": 300
    },
    "id": "8kK8eHs2kvde",
    "outputId": "0f47b3bf-9a24-48a1-f3b6-7d73c20e870a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: 28456, X_valid: 9485, X_test: 9486, y_train: 28456, y_valid: 9485, y_test: 9486\n"
     ]
    }
   ],
   "source": [
    "X_train1, X_valid1, X_test1, y_train1, y_valid1, y_test1 = cf.train_valid_test_split(X_gensim_cleaned_X, y, 0.6, 0.2, 0.2, stratify=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gc_PdMMHkx5a"
   },
   "outputs": [],
   "source": [
    "X_train_subset2, y_train_subset2, X_valid_subset2, y_valid_subset2 = X_train1[:100], y_train1[:100], X_valid1[:100], y_valid1[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ap_G5fyZlDTf"
   },
   "source": [
    "# Custom Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JJI4qfGqk7Pe"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"IMDB dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        self.X = np.array(X)\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        text = self.X[idx]\n",
    "        labels = self.y[idx]\n",
    "        sample = (text, labels)\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rG5osO9VlGe5"
   },
   "outputs": [],
   "source": [
    "trainset = CustomDataset(X_train,y_train)\n",
    "validset = CustomDataset(X_valid,y_valid)\n",
    "testset = CustomDataset(X_test,y_test)\n",
    "# trainset_gen = CustomDataset(X_train1,y_train1)\n",
    "# validset_gen = CustomDataset(X_valid1,y_valid1)\n",
    "# testset_gen = CustomDataset(X_test1,y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1651383529689,
     "user": {
      "displayName": "Vikash Kumar",
      "userId": "09277849211533188513"
     },
     "user_tz": 300
    },
    "id": "NsIlENS-mnsF",
    "outputId": "c4c36e33-4264-4800-a1e3-7f1c885c31ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['code multiple button navigation java activitiesquestion 1 2 activity wonder optimize create 2 activity multiple listener create multiple java file button(onclick listener question 2 try create multiple listener java button work syntax multiple listener java file update code issue matter button click lead page      package import activity import context import intent import bundle import button import view import view onclicklistener   public class activity1 extend activity2   button button1 button button2 button button3 button button4 button button5 button button6   public void oncreate(bundle savedinstancestate      super.oncreate(savedinstancestate      setcontentview(r.layout.fineline      addlisteneronbutton      public void addlisteneronbutton   final context context =   button1 = button findviewbyid(r.id.autobody   button1.setonclicklistener(new onclicklistener        public void onclick(view arg0           intent intent = new intent(context          startactivity(intent              button2 = button findviewbyid(r.id.glas   button2.setonclicklistener(new onclicklistener       override      public void onclick(view arg0           intent intent = new intent(context          startactivity(intent              button3 = button findviewbyid(r.id.wheels   button3.setonclicklistener(new onclicklistener       override      public void onclick(view arg0           intent intent = new intent(context          startactivity(intent              button4 = button findviewbyid(r.id.speedy   button4.setonclicklistener(new onclicklistener       override      public void onclick(view arg0           intent intent = new intent(context          startactivity(intent              button5 = button findviewbyid(r.id.sevan   button5.setonclicklistener(new onclicklistener       override      public void onclick(view arg0           intent intent = new intent(context          startactivity(intent              button6 = button findviewbyid(r.id.towe button6.setonclicklistener(new onclicklistener override public void onclick(view arg0       intent intent = new intent(context      startactivity(intent              package   import activity import bundle import button   public class activity2 extend activity   button button1   public void oncreate1(bundle savedinstancestate super.oncreate(savedinstancestate setcontentview(r.layout.autobody button button2   public void oncreate2(bundle savedinstancestate super.oncreate(savedinstancestate setcontentview(r.layout.glass button button3   public void oncreate3(bundle savedinstancestate super.oncreate(savedinstancestate setcontentview(r.layout.wheel button button4   public void oncreate(bundle savedinstancestate super.oncreate(savedinstancestate setcontentview(r.layout.speedy button button5   public void oncreate5(bundle savedinstancestate super.oncreate(savedinstancestate setcontentview(r.layout.sevan   button button6   public void oncreate6(bundle savedinstancestate super.oncreate(savedinstancestate setcontentview(r.layout.towe    '],\n",
       "       dtype='<U30138'), array([[0, 1, 0, 0, 1, 0, 0, 0, 0, 0]]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.__getitem__([11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9wVLN8LmudX0"
   },
   "outputs": [],
   "source": [
    "# trainset_gen.__getitem__([11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rwTbZe9GmtX6"
   },
   "outputs": [],
   "source": [
    "def create_vocab(dataset, min_freq):\n",
    "  counter = Counter()\n",
    "  for (text, _) in dataset:\n",
    "    counter.update(str(text).split())\n",
    "  my_vocab = vocab(counter, min_freq=min_freq)\n",
    "  my_vocab.insert_token('<unk>', 0)\n",
    "  my_vocab.set_default_index(0)\n",
    "  return my_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q1AIO-b4nEQz"
   },
   "outputs": [],
   "source": [
    "trainset_vocab = create_vocab(trainset, min_freq = 2)\n",
    "# trainset_gen_vocab = create_vocab(trainset_gen, min_freq = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1651383533434,
     "user": {
      "displayName": "Vikash Kumar",
      "userId": "09277849211533188513"
     },
     "user_tz": 300
    },
    "id": "heu_NdW4nt5h",
    "outputId": "8956096d-0fb0-44e1-d122-ac60a6d3ff27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94213\n"
     ]
    }
   ],
   "source": [
    "print(len(trainset_vocab))\n",
    "# print(len(trainset_gen_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1651383533434,
     "user": {
      "displayName": "Vikash Kumar",
      "userId": "09277849211533188513"
     },
     "user_tz": 300
    },
    "id": "Top8XfLnn0qB",
    "outputId": "38793724-ce11-4cc6-cf2a-8d758a9c0327"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', 'rearrange', 'order', 'list', 'web', 'page', 'base', 'current', \"day?i'm\", 'work', 'site', 'restaurant', 'daily', 'specials', 'take', 'vertical', 'space', '<', 'li', '>']\n"
     ]
    }
   ],
   "source": [
    "print(trainset_vocab.get_itos()[0:20])\n",
    "# print(trainset_gen_vocab.get_itos()[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lOVOARyjovXW"
   },
   "outputs": [],
   "source": [
    "# print_itos = list(set(trainset_vocab.get_itos()) - set(trainset_gen_vocab.get_itos()))\n",
    "# print(print_itos[:10])\n",
    "# print_itos = list(set(trainset_vocab.get_itos()) & set(trainset_gen_vocab.get_itos()))\n",
    "# print(print_itos[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1651383533548,
     "user": {
      "displayName": "Vikash Kumar",
      "userId": "09277849211533188513"
     },
     "user_tz": 300
    },
    "id": "qEUb8bNHqoiv",
    "outputId": "9f99eec0-7911-4887-8e56-234cb2f4c72d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21825"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset_vocab['dotnet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4-7sHu6Sr481"
   },
   "outputs": [],
   "source": [
    "# trainset_gen_vocab['dotnet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fWxoajpnr-7w"
   },
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: [trainset_vocab[token] for token in str(x).split()]\n",
    "# text_pipeline_gen = lambda x: [trainset_gen_vocab[token] for token in str(x).split()]\n",
    "label_pipeline = lambda x: int(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r8ygGeEFuqzD"
   },
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "    for (_text, _label) in batch:\n",
    "         label_list.append(torch.tensor(_label).float())\n",
    "         processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "         text_list.append(processed_text)\n",
    "         offsets.append(processed_text.size(0))\n",
    "    label_list = torch.stack(label_list)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text_list = torch.cat(text_list)\n",
    "    return text_list, label_list, offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HgnKMijrv_lU"
   },
   "outputs": [],
   "source": [
    "# def collate_batch_gen(batch):\n",
    "#     label_list, text_list, offsets = [], [], [0]\n",
    "#     for (_text, _label) in batch:\n",
    "#          label_list.append(label_pipeline(_label))\n",
    "#          processed_text = torch.tensor(text_pipeline_gen(_text), dtype=torch.int64)\n",
    "#          text_list.append(processed_text)\n",
    "#          offsets.append(processed_text.size(0))\n",
    "#     label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "#     offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "#     text_list = torch.cat(text_list)\n",
    "#     return text_list, label_list, offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HbqfoP3JwPGK"
   },
   "outputs": [],
   "source": [
    "batch_size=2\n",
    "check_loader = torch.utils.data.DataLoader(dataset=trainset,\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=True,\n",
    "                                            collate_fn=collate_batch,\n",
    "                                            num_workers=cores-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 275,
     "status": "ok",
     "timestamp": 1651383533821,
     "user": {
      "displayName": "Vikash Kumar",
      "userId": "09277849211533188513"
     },
     "user_tz": 300
    },
    "id": "YVctuoIMyuZP",
    "outputId": "6cafc8a0-f0a6-4655-8670-1ae3db9324f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 1.]]) tensor([ 3011,    25, 64508, 50105,  3011,   694, 32605,  3011,  6034,   139,\n",
      "        13188,   196,   534,   739,   523,   739,   175,   739,  1818,  1849,\n",
      "         1023,   374,  2020,  1311,   739,   531,    74,  1052,  9397,   858,\n",
      "          411,   784,     4,   803,  9398,   330,   511,    60,  1052,    29,\n",
      "          374,    74,  9399,  1239,   502,     5,    29,    57,   537,  1052,\n",
      "            5,    29,    73,   537,  1239,     5,     9,   806,    29,   374,\n",
      "           74,    34,    57,  9400,     3,  9400,  1052,    73,  9400,   343,\n",
      "         1239,    57,  9401,     3,  9401,  1052,    73,  9401,  1239,   374,\n",
      "            3,  9401,    73,  9401,  1239,   806,   775,   330,    93,    29,\n",
      "          111,  9401,  1239,  9401,    57,  9402,  9400,  1239,  9400,    57,\n",
      "           92,    29,    73,  9400,    57,    92,   609,   518,  1239,     5,\n",
      "          699,  9401,   609,   518,  9085,    57,   166,   701,   504,  3365,\n",
      "          612,  2842,    29,  1142,     5,  4773,     5,  9403,    60,   166,\n",
      "          126,  1807,  1019,   116,    57,     5,   166,  2842,   612,   514,\n",
      "           29,    73,   343,  9404,  2842,  4773,   612,  1239,   166,  2490,\n",
      "          612,  1151,   519,   521,    21,   592,  1172,   330,   204,  1967,\n",
      "         2848,   489,    32,   124,  9405,  1151,   531,  1166,   208,  1769,\n",
      "          209,    57,   154,     4,  1771,   208,   159,  9406,  3309,   502,\n",
      "           57,   663,   208,   159,  9407,  1593,  5388,   537,  1052,  9408,\n",
      "          819,    76,  9409,   166,  2185,  9410,    81,  9411,  9412,  9413,\n",
      "           81,  9410,  9414,   196,   847,   197,  9415,    85,    81,   556,\n",
      "           60,   187,   197,  1178,    75,    76,  9416,    77,    78,    79,\n",
      "         9417,  1052,    94,   537,  1239,     5,  1699,  1981,    81,  9418,\n",
      "         9419,    81,  1981,  2515,  1435,   556,  1239,     5,   125,  9408,\n",
      "         4153,  9420,    81,  9419,   126,  9421,  9422,    57,     5,   323,\n",
      "            5,  9423,  1914,   125,  9424,    75,    76,  1231,    77,    78,\n",
      "           79,  9425,  1019,  9426,  9427,  9428,    81,  4153,  9429,  9409,\n",
      "          819,  1132,  9425,  9430,    81,    81,   788,   558,    86,  9431,\n",
      "           81,    81,   788,   558,    86,  9432,    81,    81,  9433,   558,\n",
      "           86,   558,    83,   819,    76,  9427,   358,  9434,    81,   358,\n",
      "         5560,  9435,  9434,   107,  9436,  9434]) tensor([ 0, 26])\n"
     ]
    }
   ],
   "source": [
    "for text, label, offsets in check_loader:\n",
    "  print(label, text, offsets)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2vHj4FkU_-Su"
   },
   "outputs": [],
   "source": [
    "# Fix seed value\n",
    "SEED = 2345\n",
    "random.seed(SEED)\n",
    "\n",
    "# We will be using 500 observations for text and 100 for valid daatset\n",
    "# We do not need valid for overfitting, it will help to check errors in code\n",
    "train_sample_size = 500\n",
    "valid_sample_size = 100\n",
    "\n",
    "# Getting n random indices\n",
    "train_subset_indices = random.sample(range(0, len(trainset)), train_sample_size)\n",
    "valid_subset_indices = random.sample(range(0, len(validset)), valid_sample_size)\n",
    "\n",
    "# Getting subset of dataset\n",
    "train_subset = torch.utils.data.Subset(trainset, train_subset_indices)\n",
    "valid_subset = torch.utils.data.Subset(validset, valid_subset_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vMznW_2Dy5s_"
   },
   "outputs": [],
   "source": [
    "pretrained_vectors1000 = gensim.models.KeyedVectors.load_word2vec_format('/content/drive/MyDrive/Datasets_Models/Word_Embeddings/GoogleNews-vectors-negative300.bin', binary=True, limit=1000)\n",
    "pretrained_vectors1000000 = gensim.models.KeyedVectors.load_word2vec_format('/content/drive/MyDrive/Datasets_Models/Word_Embeddings/GoogleNews-vectors-negative300.bin', binary=True, limit=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1651383554935,
     "user": {
      "displayName": "Vikash Kumar",
      "userId": "09277849211533188513"
     },
     "user_tz": 300
    },
    "id": "V-9iC0_k4xUT",
    "outputId": "c0c02d41-7ee7-4167-fc1c-07abebe4f088"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = pretrained_vectors1000.wv.get_vector('office')\n",
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TLPDix9543Y5"
   },
   "outputs": [],
   "source": [
    "embedding_dim =300\n",
    "test_weights = np.zeros((2, embedding_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NrbyynYI9nB5"
   },
   "outputs": [],
   "source": [
    "test_weights[0] = pretrained_vectors1000.wv.get_vector('office')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QbCk86xI9uHK"
   },
   "outputs": [],
   "source": [
    "test_weights[1] =  np.random.normal(size=(embedding_dim, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vFgSq71n9xty"
   },
   "outputs": [],
   "source": [
    "embedding_dim = 300\n",
    "pretrained_weights = np.zeros((len(trainset_vocab), embedding_dim))\n",
    "words_found = 0\n",
    "words_not_found = 0\n",
    "\n",
    "for i, word in enumerate(trainset_vocab.get_itos()):\n",
    "    try: \n",
    "        pretrained_weights[i] = pretrained_vectors1000000.wv.get_vector(word)\n",
    "        words_found += 1\n",
    "    except KeyError:\n",
    "        words_not_found  += 1\n",
    "        pretrained_weights[i] = np.random.normal(size=(embedding_dim, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1651383558050,
     "user": {
      "displayName": "Vikash Kumar",
      "userId": "09277849211533188513"
     },
     "user_tz": 300
    },
    "id": "VTy4OTnw9_5-",
    "outputId": "1c794b4e-6ee6-4ca7-a4bf-dd4d8110a50f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9234"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1651383558050,
     "user": {
      "displayName": "Vikash Kumar",
      "userId": "09277849211533188513"
     },
     "user_tz": 300
    },
    "id": "fgtJvYQr-Gzm",
    "outputId": "588ac24d-705f-489f-f895-c16e5ea68e9e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84979"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_not_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1dtUwJ4M-ImE"
   },
   "outputs": [],
   "source": [
    "class MLPCustom(nn.Module):\n",
    "  def __init__(self, vocab_size, hidden_sizes_list, dprobs_list, batchnorm_binary, output_dim, non_linearity, pretrained_weights):\n",
    "\n",
    "    \n",
    "\n",
    "    self.vocab_size = vocab_size\n",
    "    \n",
    "\n",
    "    self.hidden_sizes_list = hidden_sizes_list # hidden_sizes = [emb_dim, hidden_dim1, hidden_dim2, .....output_dim] # n + 1 elements\n",
    "    self.dprobs_list = dprobs_list # dpropb =[prob1, prob2....probn] # n elements\n",
    "    self.batchnorm_binary  = batchnorm_binary  # True or False\n",
    "    self.output_dim = output_dim\n",
    "    self.non_linearity = non_linearity\n",
    "\n",
    "    self.pretrained_weights = pretrained_weights\n",
    "    # self.task = task\n",
    "    \n",
    "\n",
    "    super().__init__()\n",
    "\n",
    "    # embedding_layer\n",
    "    \n",
    "    # if self.task == 2:\n",
    "    #    self.embedding_layer = nn.EmbeddingBag(vocab_size, self.hidden_sizes_list[0])\n",
    "\n",
    "    # Task 5\n",
    "    # if self.task == 5:\n",
    "    self.embedding_layer = nn.EmbeddingBag(vocab_size, self.hidden_sizes_list[0]).from_pretrained(pretrained_weights,\n",
    "                                                                               freeze = True)\n",
    "       \n",
    "    # Task 6\n",
    "    # if self.task == 6:\n",
    "    #    self.embedding_layer = nn.EmbeddingBag(vocab_size, self.hidden_sizes_list[0]).from_pretrained(pretrained_weights,\n",
    "    #                                                                            freeze = False)\n",
    "\n",
    "    # hidden layers\n",
    "    self.hidden_layers = nn.ModuleList()\n",
    "\n",
    "    # dropout layers\n",
    "    self.dropout_layers = nn.ModuleList()\n",
    "\n",
    "    # batchnorm layers\n",
    "    self.batchnorm_layers = nn.ModuleList()\n",
    "\n",
    "    for k in range(len(self.hidden_sizes_list)-1):\n",
    "      self.hidden_layers.append(nn.Linear(self.hidden_sizes_list[k], self.hidden_sizes_list[k+1]))\n",
    "      self.dropout_layers.append(nn.Dropout(p=self.dprobs_list[k]))\n",
    "\n",
    "      if self.batchnorm_binary:\n",
    "        self.batchnorm_layers.append(nn.BatchNorm1d(self.hidden_sizes_list[k+1], momentum=0.9))\n",
    "\n",
    "    self.output_layer = nn.Linear(self.hidden_sizes_list[-1], self.output_dim)\n",
    "\n",
    "   \n",
    "\n",
    "  def forward(self, input, offsets):\n",
    "    x = self.embedding_layer(input, offsets)\n",
    "    for  k in range(len(self.hidden_sizes_list)-1):\n",
    "      x =  self.non_linearity(self.hidden_layers[k](x))\n",
    "      if self.batchnorm_binary:\n",
    "        x = self.batchnorm_layers[k](x)\n",
    "      x= self.dropout_layers[k](x)\n",
    "\n",
    "    x = self.output_layer(x)\n",
    "    return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "763VdafI-i0o"
   },
   "outputs": [],
   "source": [
    "def train(train_loader, model, optimizer, loss_function, log_batch, log_interval, grad_clipping, max_norm):\n",
    "\n",
    "  \"\"\" \n",
    "  Function for training the model in each epoch\n",
    "  Input: iterator for train dataset, initial weights and bias, epochs, learning rate.\n",
    "  Output: final weights, bias, train loss, train accuracy\n",
    "  \"\"\"\n",
    "  # initilalize variables as global\n",
    "  # these counts will be updated every epoch\n",
    "  global example_ct_train\n",
    "  global batch_ct_train\n",
    "  \n",
    "\n",
    "  # Training Loop loop\n",
    "  # Initialize train_loss at the he start of the epoch\n",
    "  running_train_loss = 0\n",
    "\n",
    "  #running_train_correct = 0\n",
    "  \n",
    "  # put the model in training mode\n",
    "  model.train()\n",
    "\n",
    "  # Iterate on batches from the dataset using train_loader\n",
    "  for text, targets, offsets in train_loader:\n",
    "    \n",
    "    # move inputs and outputs to GPUs\n",
    "    text = text.to(device)\n",
    "    targets = targets.to(device)\n",
    "    offsets = offsets.to(device)\n",
    "    \n",
    "    # Forward pass\n",
    "    output = model(text, offsets)\n",
    "    loss = loss_function(output, targets)\n",
    "    \n",
    "    # set gradients to zero \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Correct prediction\n",
    "    #y_pred = torch.argmax(output, dim = 1)\n",
    "    #correct = torch.sum(y_pred == targets)\n",
    "\n",
    "    example_ct_train +=  len(targets)\n",
    "    batch_ct_train += 1\n",
    "\n",
    "    # Gradient Clipping\n",
    "    if grad_clipping:\n",
    "      nn.utils.clip_grad_norm_(model.parameters(), max_norm=max_norm, norm_type=2)\n",
    "\n",
    "    # Update parameters using their gradient\n",
    "    optimizer.step()\n",
    "\n",
    "    # Add train loss of a batch \n",
    "    running_train_loss += loss.item()\n",
    "\n",
    "    # Add Corect counts of a batch\n",
    "    #running_train_correct += correct\n",
    "\n",
    "    # log batch loss and accuracy\n",
    "    if log_batch:\n",
    "      if ((batch_ct_train + 1) % log_interval) == 0:\n",
    "        wandb.log({f\"Train Batch Loss  :\": loss})\n",
    "        #wandb.log({f\"Train Batch Acc :\": correct/len(targets)})\n",
    "\n",
    "  \n",
    "  # Calculate mean train loss for the whole dataset for a particular epoch\n",
    "  train_loss = running_train_loss/len(train_loader)\n",
    "\n",
    "\n",
    "  # Calculate accuracy for the whole dataset for a particular epoch\n",
    "  #train_acc = running_train_correct/len(train_loader.dataset)\n",
    "\n",
    "  return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nl6FDWP9-p8U"
   },
   "outputs": [],
   "source": [
    "def valid(loader, model, optimizer, loss_function, log_batch, log_interval):\n",
    "\n",
    "  \"\"\" \n",
    "  Function for training the model and plotting the graph for train & valid loss vs epoch.\n",
    "  Input: iterator for train dataset, initial weights and bias, epochs, learning rate, batch size.\n",
    "  Output: final weights, bias and train loss and valid loss for each epoch.\n",
    "  \"\"\"\n",
    "\n",
    "  # initilalize variables as global\n",
    "  # these counts will be updated every epoch\n",
    "  global example_ct_valid\n",
    "  global batch_ct_valid\n",
    "\n",
    "  # Validation loop\n",
    "  # Initialize train_loss at the he strat of the epoch\n",
    "  running_valid_loss = 0\n",
    "  #running_valid_correct = 0\n",
    "  \n",
    "  # put the model in evaluation mode\n",
    "  model.eval()\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for text, targets, offsets in loader:\n",
    "      \n",
    "      # move inputs and outputs to GPUs\n",
    "      text = text.to(device)\n",
    "      targets = targets.to(device)\n",
    "      offsets = offsets.to(device)\n",
    "      \n",
    "      # Forward pass\n",
    "      output = model(text, offsets)\n",
    "      loss = loss_function(output,targets)\n",
    "\n",
    "      # Correct Predictions\n",
    "      #y_pred = torch.argmax(output, dim = 1)\n",
    "      #correct = torch.sum(y_pred == targets)\n",
    "\n",
    "      # count of images and batches\n",
    "      example_ct_valid +=  len(targets)\n",
    "      batch_ct_valid += 1\n",
    "\n",
    "      # Add valid loss of a batch \n",
    "      running_valid_loss += loss.item()\n",
    "\n",
    "      # Add correct count for each batch\n",
    "      #running_valid_correct += correct\n",
    "\n",
    "      # log batch loss and accuracy\n",
    "      if log_batch:\n",
    "        if ((batch_ct_valid + 1) % log_interval) == 0:\n",
    "          wandb.log({f\"Valid Batch Loss  :\": loss})\n",
    "          #wandb.log({f\"Valid Batch Accuracy :\": correct/len(targets)})\n",
    "\n",
    "\n",
    "    # Calculate mean valid loss for the whole dataset for a particular epoch\n",
    "    valid_loss = running_valid_loss/len(valid_loader)\n",
    "\n",
    "    # scheduler step for learning rate on Plateau\n",
    "    scheduler.step(valid_loss)\n",
    "\n",
    "    # scheduler step for stepLR\n",
    "    # scheduler.step()\n",
    "\n",
    "    # Calculate accuracy for the whole dataset for a particular epoch\n",
    "    #valid_acc = running_valid_correct/len(valid_loader.dataset)\n",
    "    \n",
    "  return valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3o5bncjW-ru_"
   },
   "outputs": [],
   "source": [
    "def train_loop(train_loader, valid_loader, model, loss_function, optimizer, epochs, device, \n",
    "               patience, early_stopping,\n",
    "               file_model, save_best_model):\n",
    "\n",
    "  '''\n",
    "  model: specify your model for training\n",
    "  criterion: loss function \n",
    "  optimizer: optimizer like SGD , ADAM etc.\n",
    "  train loader: function to carete batches for training data\n",
    "  valid loader : function to create batches for valid data set\n",
    "  file_model : specify file name for saving your model. This way we can upload the model weights from file. We will not to run model again.\n",
    "  \n",
    "\n",
    "  '''\n",
    "  # Create lists to store train and valid loss at each epoch\n",
    "\n",
    "  train_loss_history = []\n",
    "  valid_loss_history = []\n",
    "  #train_acc_history = []\n",
    "  #valid_acc_history = []\n",
    "  delta = 0\n",
    "  best_score = None\n",
    "  valid_loss_min = np.Inf\n",
    "  counter_early_stop=0\n",
    "  early_stop=False\n",
    "\n",
    "\n",
    "  # Iterate for the given number of epochs\n",
    "  for epoch in range(epochs):\n",
    "    t0 = datetime.now()\n",
    "    # Get train loss and accuracy for one epoch\n",
    "\n",
    "    train_loss = train(train_loader, model, optimizer, loss_function, \n",
    "                                  wandb.config.LOG_BATCH, wandb.config.LOG_INTERVAL,\n",
    "                                  wandb.config.GRAD_CLIPPING, wandb.config.MAX_NORM)\n",
    "    valid_loss = valid(valid_loader, model, optimizer, loss_function,\n",
    "                                    wandb.config.LOG_BATCH, wandb.config.LOG_INTERVAL)\n",
    "\n",
    "    dt = datetime.now() - t0\n",
    "\n",
    "    # Save history of the Losses and accuracy\n",
    "    train_loss_history.append(train_loss)\n",
    "    #train_acc_history.append(train_acc)\n",
    "    valid_loss_history.append(valid_loss)\n",
    "    #valid_acc_history.append(valid_acc)\n",
    "\n",
    "    if early_stopping:\n",
    "      score = -valid_loss\n",
    "      if best_score is None:\n",
    "        best_score=score\n",
    "        print(f'Validation loss has decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}). Saving Model...')\n",
    "        torch.save(model.state_dict(), file_model)\n",
    "        valid_loss_min = valid_loss\n",
    "\n",
    "      elif score < best_score + delta:\n",
    "        counter_early_stop += 1\n",
    "        print(f'Early stoping counter: {counter_early_stop} out of {patience}')\n",
    "        if counter_early_stop > patience:\n",
    "          early_stop = True\n",
    "\n",
    "      \n",
    "      else:\n",
    "        best_score = score\n",
    "        print(f'Validation loss has decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}). Saving model...')\n",
    "        torch.save(model.state_dict(), file_model)\n",
    "        counter_early_stop=0\n",
    "        valid_loss_min = valid_loss\n",
    "\n",
    "      if early_stop:\n",
    "        print('Early Stopping')\n",
    "        break\n",
    "\n",
    "    elif save_best_model:\n",
    "\n",
    "      score = -valid_loss\n",
    "      if best_score is None:\n",
    "        best_score=score\n",
    "        print(f'Validation loss has decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}). Saving Model...')\n",
    "        torch.save(model.state_dict(), file_model)\n",
    "        valid_loss_min = valid_loss\n",
    "\n",
    "      elif score < best_score + delta:\n",
    "        print(f'Validation loss has not decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}). Not Saving Model...')\n",
    "      \n",
    "      else:\n",
    "        best_score = score\n",
    "        print(f'Validation loss has decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}). Saving model...')\n",
    "        torch.save(model.state_dict(), file_model)\n",
    "        valid_loss_min = valid_loss\n",
    "\n",
    "    else:\n",
    "        torch.save(model.state_dict(), file_model)\n",
    "\n",
    "    # Log the train and valid loss to W&B\n",
    "    wandb.log({f\"Train epoch Loss :\": train_loss, f\"Valid epoch Loss :\": valid_loss })\n",
    "    #wandb.log({f\"Train epoch Acc :\": train_acc, f\"Valid epoch Acc :\": valid_acc})\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Print the train loss and accuracy for given number of epochs, batch size and number of samples\n",
    "    print(f'Epoch : {epoch+1} / {epochs}')\n",
    "    print(f'Time to complete {epoch+1} is {dt}')\n",
    "    print(f'Learning rate: {scheduler._last_lr[0]}')\n",
    "    \n",
    "    #print(f'Train Loss: {train_loss : .4f} | Train Accuracy: {train_acc * 100 : .4f}%')\n",
    "    #print(f'Valid Loss: {valid_loss : .4f} | Valid Accuracy: {valid_acc * 100 : .4f}%')\n",
    "    \n",
    "    print(f'Train Loss: {train_loss : .4f}')\n",
    "    print(f'Valid Loss: {valid_loss : .4f}')\n",
    "    print()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "  #return train_loss_history, train_acc_history, valid_loss_history, valid_acc_history\n",
    "  return train_loss_history, valid_loss_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w2hLhgL5-tQE"
   },
   "outputs": [],
   "source": [
    "hyperparameters = dict(\n",
    "    \n",
    "    HIDDEN_SIZES_LIST = [300] + [200],  # 300 = embed_dim \n",
    "    DPROBS_LIST = [0.0] + [0] ,\n",
    "    BATCHNORM_BINARY = False,\n",
    "    TASK = 5,\n",
    "    \n",
    "    VOCAB_SIZE = len(trainset_vocab),\n",
    "    OUTPUT_DIM = 10,\n",
    "\n",
    "    EPOCHS = 100, \n",
    "    \n",
    "    BATCH_SIZE = 256, \n",
    "    LEARNING_RATE = 0.02, \n",
    "    DATASET=\"StackOverFlow\",\n",
    "    ARCHITECTURE=\"embedding_layer_only\", \n",
    "    LOG_INTERVAL = 25,\n",
    "    LOG_BATCH = True,\n",
    "    FILE_MODEL = model_path/'overfit_exp1.pt',\n",
    "    GRAD_CLIPPING = False,  \n",
    "    MAX_NORM = 0, \n",
    "    MOMENTUM = 0, \n",
    "    PATIENCE = 10,\n",
    "    EARLY_STOPPING = True,\n",
    "    SAVE_BEST_MODEL = False,\n",
    "    SCHEDULER_FACTOR = 0.8,\n",
    "    SCHEDULER_PATIENCE = 0,\n",
    "    WEIGHT_DECAY = 0.0005\n",
    "   )\n",
    "\n",
    "non_linearity = F.selu\n",
    "pretrained_weights_tensor = torch.tensor(pretrained_weights).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195,
     "referenced_widgets": [
      "6a21d846bfdd4c40bbd82789038af82d",
      "a95dcb6192214736ac100bb349923835",
      "e42ce56a290442c1bcf486514416fb2e",
      "276c5c617a1a48088f67054c5fabebde",
      "4a5e8c5b38a8467fae762fbc6cbdb4e0",
      "5310ec8231004042b2853697aed2248e",
      "f7fabda30572452cae2aeee06afb57d1",
      "0cb2c24c742746eda4069d5e326749b7"
     ]
    },
    "executionInfo": {
     "elapsed": 9577,
     "status": "ok",
     "timestamp": 1651383856984,
     "user": {
      "displayName": "Vikash Kumar",
      "userId": "09277849211533188513"
     },
     "user_tz": 300
    },
    "id": "-UTKKuZB_LQs",
    "outputId": "7f169331-615b-420a-a01e-a56ccc7dbda7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:li83jmtp) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a21d846bfdd4c40bbd82789038af82d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">exp_1</strong>: <a href=\"https://wandb.ai/vikashk/hw6_part_b_full_task5/runs/li83jmtp\" target=\"_blank\">https://wandb.ai/vikashk/hw6_part_b_full_task5/runs/li83jmtp</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220501_054212-li83jmtp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:li83jmtp). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.15"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220501_054405-5h5vbxra</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/vikashk/hw6_part_b_full_task5/runs/5h5vbxra\" target=\"_blank\">exp_1</a></strong> to <a href=\"https://wandb.ai/vikashk/hw6_part_b_full_task5\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/vikashk/hw6_part_b_full_task5/runs/5h5vbxra?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f7bd0050510>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(name = 'exp_1', project = 'hw6_part_b_full_task5', config = hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yBYcJ5Ec_QRw"
   },
   "outputs": [],
   "source": [
    "wandb.config.NON_LINEARITY = non_linearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X6xFxr0W_TzV"
   },
   "outputs": [],
   "source": [
    "# Fix seed value\n",
    "from datetime import datetime\n",
    "SEED = 2345\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# Data Loader\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=wandb.config.BATCH_SIZE, shuffle =True, \n",
    "                                           collate_fn=collate_batch, num_workers = 4)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(validset, batch_size=wandb.config.BATCH_SIZE, shuffle = False, \n",
    "                                           collate_fn=collate_batch,  num_workers = 4)\n",
    "                                         \n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=wandb.config.BATCH_SIZE, shuffle = False, \n",
    "                                           collate_fn=collate_batch,  num_workers = 4)\n",
    "\n",
    "# cross entropy loss function\n",
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# use GPUs\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# model \n",
    "                \n",
    "model_hw6_part_b_task5  = MLPCustom(wandb.config.VOCAB_SIZE, \n",
    "                                    wandb.config.HIDDEN_SIZES_LIST, \n",
    "                                    wandb.config.DPROBS_LIST, \n",
    "                                    wandb.config.BATCHNORM_BINARY, \n",
    "                                    wandb.config.OUTPUT_DIM, \n",
    "                                    non_linearity, pretrained_weights_tensor)\n",
    "\n",
    "model_hw6_part_b_task5.to(device)\n",
    "\n",
    "def init_weights(m):\n",
    "  if type(m) == nn.Linear:\n",
    "      #torch.nn.init.normal_(m.weight, mean = 0, std = 1)\n",
    "      torch.nn.init.kaiming_normal_(m.weight)\n",
    "      torch.nn.init.zeros_(m.bias)\n",
    "\n",
    "  #if type(m) == nn.EmbeddingBag:\n",
    "      #torch.nn.init.normal_(m.weight, mean = 0, std = 1)\n",
    "        \n",
    "# apply initialization recursively  to all modules\n",
    "# model_hw6_part_a.apply(init_weights)\n",
    "\n",
    "wandb.config.initialization = 'Default'\n",
    "\n",
    "# Intialize stochiastic gradient descent optimizer\n",
    "#optimizer = torch.optim.SGD(model_imdb.parameters(), lr = wandb.config.LEARNING_RATE, \n",
    "#                            weight_decay=wandb.config.WEIGHT_DECAY, momentum = wandb.config.MOMENTUM)\n",
    "\n",
    "optimizer = torch.optim.Adam(model_hw6_part_b_task5.parameters(), lr = wandb.config.LEARNING_RATE, \n",
    "                            weight_decay=wandb.config.WEIGHT_DECAY)\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor= wandb.config.SCHEDULER_FACTOR, \n",
    "                              patience=wandb.config.SCHEDULER_PATIENCE, verbose=True)\n",
    "\n",
    "# scheduler = StepLR(optimizer, gamma=0.4,step_size=1, verbose=True)\n",
    "\n",
    "wandb.config.optimizer = optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1559,
     "status": "ok",
     "timestamp": 1651383859039,
     "user": {
      "displayName": "Vikash Kumar",
      "userId": "09277849211533188513"
     },
     "user_tz": 300
    },
    "id": "Ta2H-EnXAWZN",
    "outputId": "8772d1fb-e0c7-4bc2-9c92-1b43ce3fb4a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual loss: 0.701297402381897\n",
      "Expected Theoretical loss: 0.6931471805599453\n"
     ]
    }
   ],
   "source": [
    "# Fix seed value\n",
    "\n",
    "SEED = 2345\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "for text , targets, offsets in train_loader:\n",
    "  \n",
    "  # move inputs and outputs to GPUs\n",
    "  text = text.to(device)\n",
    "  targets = targets.to(device)\n",
    "  offsets = offsets.to(device)\n",
    "  \n",
    "  model_hw6_part_b_task5.eval()\n",
    "  # Forward pass\n",
    "  output = model_hw6_part_b_task5(text, offsets)\n",
    "  loss = loss_function(output, targets)\n",
    "  print(f'Actual loss: {loss}')\n",
    "  break\n",
    "\n",
    "print(f'Expected Theoretical loss: {np.log(2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 98,
     "status": "ok",
     "timestamp": 1651383863275,
     "user": {
      "displayName": "Vikash Kumar",
      "userId": "09277849211533188513"
     },
     "user_tz": 300
    },
    "id": "VZ6aAtVIAvVV",
    "outputId": "1b6e87a3-8bae-4ed8-dea2-52be5ba90179"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<wandb.wandb_torch.TorchGraph at 0x7f7ba7358850>]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.watch(model_hw6_part_b_task5, log = 'all', log_freq=25, log_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 701977,
     "status": "ok",
     "timestamp": 1651384566862,
     "user": {
      "displayName": "Vikash Kumar",
      "userId": "09277849211533188513"
     },
     "user_tz": 300
    },
    "id": "AtPuXU6VA_S2",
    "outputId": "5ed3bb94-d7a0-4b51-d49a-0ef8bfaa46b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss has decreased (inf --> 0.256544). Saving Model...\n",
      "Epoch : 1 / 100\n",
      "Time to complete 1 is 0:00:14.471851\n",
      "Learning rate: 0.02\n",
      "Train Loss:  0.2887\n",
      "Valid Loss:  0.2565\n",
      "\n",
      "Validation loss has decreased (0.256544 --> 0.250405). Saving model...\n",
      "Epoch : 2 / 100\n",
      "Time to complete 2 is 0:00:14.894054\n",
      "Learning rate: 0.02\n",
      "Train Loss:  0.2559\n",
      "Valid Loss:  0.2504\n",
      "\n",
      "Epoch 00003: reducing learning rate of group 0 to 1.6000e-02.\n",
      "Early stoping counter: 1 out of 10\n",
      "Epoch : 3 / 100\n",
      "Time to complete 3 is 0:00:14.890597\n",
      "Learning rate: 0.016\n",
      "Train Loss:  0.2534\n",
      "Valid Loss:  0.2525\n",
      "\n",
      "Validation loss has decreased (0.250405 --> 0.246192). Saving model...\n",
      "Epoch : 4 / 100\n",
      "Time to complete 4 is 0:00:14.381013\n",
      "Learning rate: 0.016\n",
      "Train Loss:  0.2467\n",
      "Valid Loss:  0.2462\n",
      "\n",
      "Epoch 00005: reducing learning rate of group 0 to 1.2800e-02.\n",
      "Early stoping counter: 1 out of 10\n",
      "Epoch : 5 / 100\n",
      "Time to complete 5 is 0:00:14.973292\n",
      "Learning rate: 0.0128\n",
      "Train Loss:  0.2474\n",
      "Valid Loss:  0.2540\n",
      "\n",
      "Validation loss has decreased (0.246192 --> 0.237999). Saving model...\n",
      "Epoch : 6 / 100\n",
      "Time to complete 6 is 0:00:13.922576\n",
      "Learning rate: 0.0128\n",
      "Train Loss:  0.2452\n",
      "Valid Loss:  0.2380\n",
      "\n",
      "Validation loss has decreased (0.237999 --> 0.237577). Saving model...\n",
      "Epoch : 7 / 100\n",
      "Time to complete 7 is 0:00:17.586664\n",
      "Learning rate: 0.0128\n",
      "Train Loss:  0.2435\n",
      "Valid Loss:  0.2376\n",
      "\n",
      "Epoch 00008: reducing learning rate of group 0 to 1.0240e-02.\n",
      "Early stoping counter: 1 out of 10\n",
      "Epoch : 8 / 100\n",
      "Time to complete 8 is 0:00:14.675624\n",
      "Learning rate: 0.01024\n",
      "Train Loss:  0.2432\n",
      "Valid Loss:  0.2455\n",
      "\n",
      "Validation loss has decreased (0.237577 --> 0.233495). Saving model...\n",
      "Epoch : 9 / 100\n",
      "Time to complete 9 is 0:00:16.269576\n",
      "Learning rate: 0.01024\n",
      "Train Loss:  0.2408\n",
      "Valid Loss:  0.2335\n",
      "\n",
      "Epoch 00010: reducing learning rate of group 0 to 8.1920e-03.\n",
      "Early stoping counter: 1 out of 10\n",
      "Epoch : 10 / 100\n",
      "Time to complete 10 is 0:00:14.842053\n",
      "Learning rate: 0.008192000000000001\n",
      "Train Loss:  0.2407\n",
      "Valid Loss:  0.2363\n",
      "\n",
      "Epoch 00011: reducing learning rate of group 0 to 6.5536e-03.\n",
      "Early stoping counter: 2 out of 10\n",
      "Epoch : 11 / 100\n",
      "Time to complete 11 is 0:00:14.659501\n",
      "Learning rate: 0.0065536000000000014\n",
      "Train Loss:  0.2393\n",
      "Valid Loss:  0.2416\n",
      "\n",
      "Epoch 00012: reducing learning rate of group 0 to 5.2429e-03.\n",
      "Early stoping counter: 3 out of 10\n",
      "Epoch : 12 / 100\n",
      "Time to complete 12 is 0:00:14.864047\n",
      "Learning rate: 0.005242880000000002\n",
      "Train Loss:  0.2382\n",
      "Valid Loss:  0.2487\n",
      "\n",
      "Epoch 00013: reducing learning rate of group 0 to 4.1943e-03.\n",
      "Early stoping counter: 4 out of 10\n",
      "Epoch : 13 / 100\n",
      "Time to complete 13 is 0:00:14.899875\n",
      "Learning rate: 0.004194304000000002\n",
      "Train Loss:  0.2380\n",
      "Valid Loss:  0.2402\n",
      "\n",
      "Epoch 00014: reducing learning rate of group 0 to 3.3554e-03.\n",
      "Early stoping counter: 5 out of 10\n",
      "Epoch : 14 / 100\n",
      "Time to complete 14 is 0:00:14.794459\n",
      "Learning rate: 0.003355443200000002\n",
      "Train Loss:  0.2366\n",
      "Valid Loss:  0.2342\n",
      "\n",
      "Validation loss has decreased (0.233495 --> 0.231215). Saving model...\n",
      "Epoch : 15 / 100\n",
      "Time to complete 15 is 0:00:15.823270\n",
      "Learning rate: 0.003355443200000002\n",
      "Train Loss:  0.2349\n",
      "Valid Loss:  0.2312\n",
      "\n",
      "Epoch 00016: reducing learning rate of group 0 to 2.6844e-03.\n",
      "Early stoping counter: 1 out of 10\n",
      "Epoch : 16 / 100\n",
      "Time to complete 16 is 0:00:16.015597\n",
      "Learning rate: 0.0026843545600000016\n",
      "Train Loss:  0.2347\n",
      "Valid Loss:  0.2371\n",
      "\n",
      "Epoch 00017: reducing learning rate of group 0 to 2.1475e-03.\n",
      "Early stoping counter: 2 out of 10\n",
      "Epoch : 17 / 100\n",
      "Time to complete 17 is 0:00:18.700091\n",
      "Learning rate: 0.0021474836480000013\n",
      "Train Loss:  0.2348\n",
      "Valid Loss:  0.2362\n",
      "\n",
      "Validation loss has decreased (0.231215 --> 0.231161). Saving model...\n",
      "Epoch : 18 / 100\n",
      "Time to complete 18 is 0:00:15.162134\n",
      "Learning rate: 0.0021474836480000013\n",
      "Train Loss:  0.2344\n",
      "Valid Loss:  0.2312\n",
      "\n",
      "Epoch 00019: reducing learning rate of group 0 to 1.7180e-03.\n",
      "Early stoping counter: 1 out of 10\n",
      "Epoch : 19 / 100\n",
      "Time to complete 19 is 0:00:14.489411\n",
      "Learning rate: 0.0017179869184000011\n",
      "Train Loss:  0.2342\n",
      "Valid Loss:  0.2331\n",
      "\n",
      "Epoch 00020: reducing learning rate of group 0 to 1.3744e-03.\n",
      "Early stoping counter: 2 out of 10\n",
      "Epoch : 20 / 100\n",
      "Time to complete 20 is 0:00:13.971085\n",
      "Learning rate: 0.001374389534720001\n",
      "Train Loss:  0.2339\n",
      "Valid Loss:  0.2315\n",
      "\n",
      "Epoch 00021: reducing learning rate of group 0 to 1.0995e-03.\n",
      "Early stoping counter: 3 out of 10\n",
      "Epoch : 21 / 100\n",
      "Time to complete 21 is 0:00:13.913857\n",
      "Learning rate: 0.001099511627776001\n",
      "Train Loss:  0.2325\n",
      "Valid Loss:  0.2325\n",
      "\n",
      "Validation loss has decreased (0.231161 --> 0.229428). Saving model...\n",
      "Epoch : 22 / 100\n",
      "Time to complete 22 is 0:00:13.975940\n",
      "Learning rate: 0.001099511627776001\n",
      "Train Loss:  0.2329\n",
      "Valid Loss:  0.2294\n",
      "\n",
      "Epoch 00023: reducing learning rate of group 0 to 8.7961e-04.\n",
      "Early stoping counter: 1 out of 10\n",
      "Epoch : 23 / 100\n",
      "Time to complete 23 is 0:00:14.511813\n",
      "Learning rate: 0.0008796093022208008\n",
      "Train Loss:  0.2323\n",
      "Valid Loss:  0.2304\n",
      "\n",
      "Epoch 00024: reducing learning rate of group 0 to 7.0369e-04.\n",
      "Early stoping counter: 2 out of 10\n",
      "Epoch : 24 / 100\n",
      "Time to complete 24 is 0:00:13.974351\n",
      "Learning rate: 0.0007036874417766407\n",
      "Train Loss:  0.2323\n",
      "Valid Loss:  0.2302\n",
      "\n",
      "Epoch 00025: reducing learning rate of group 0 to 5.6295e-04.\n",
      "Early stoping counter: 3 out of 10\n",
      "Epoch : 25 / 100\n",
      "Time to complete 25 is 0:00:14.222668\n",
      "Learning rate: 0.0005629499534213126\n",
      "Train Loss:  0.2323\n",
      "Valid Loss:  0.2297\n",
      "\n",
      "Epoch 00026: reducing learning rate of group 0 to 4.5036e-04.\n",
      "Early stoping counter: 4 out of 10\n",
      "Epoch : 26 / 100\n",
      "Time to complete 26 is 0:00:13.921460\n",
      "Learning rate: 0.0004503599627370501\n",
      "Train Loss:  0.2320\n",
      "Valid Loss:  0.2296\n",
      "\n",
      "Epoch 00027: reducing learning rate of group 0 to 3.6029e-04.\n",
      "Early stoping counter: 5 out of 10\n",
      "Epoch : 27 / 100\n",
      "Time to complete 27 is 0:00:13.896024\n",
      "Learning rate: 0.0003602879701896401\n",
      "Train Loss:  0.2319\n",
      "Valid Loss:  0.2297\n",
      "\n",
      "Epoch 00028: reducing learning rate of group 0 to 2.8823e-04.\n",
      "Early stoping counter: 6 out of 10\n",
      "Epoch : 28 / 100\n",
      "Time to complete 28 is 0:00:13.909014\n",
      "Learning rate: 0.0002882303761517121\n",
      "Train Loss:  0.2316\n",
      "Valid Loss:  0.2301\n",
      "\n",
      "Validation loss has decreased (0.229428 --> 0.229010). Saving model...\n",
      "Epoch : 29 / 100\n",
      "Time to complete 29 is 0:00:13.865654\n",
      "Learning rate: 0.0002882303761517121\n",
      "Train Loss:  0.2314\n",
      "Valid Loss:  0.2290\n",
      "\n",
      "Epoch 00030: reducing learning rate of group 0 to 2.3058e-04.\n",
      "Early stoping counter: 1 out of 10\n",
      "Epoch : 30 / 100\n",
      "Time to complete 30 is 0:00:14.335974\n",
      "Learning rate: 0.00023058430092136968\n",
      "Train Loss:  0.2312\n",
      "Valid Loss:  0.2292\n",
      "\n",
      "Epoch 00031: reducing learning rate of group 0 to 1.8447e-04.\n",
      "Early stoping counter: 2 out of 10\n",
      "Epoch : 31 / 100\n",
      "Time to complete 31 is 0:00:13.755861\n",
      "Learning rate: 0.00018446744073709575\n",
      "Train Loss:  0.2312\n",
      "Valid Loss:  0.2295\n",
      "\n",
      "Epoch 00032: reducing learning rate of group 0 to 1.4757e-04.\n",
      "Early stoping counter: 3 out of 10\n",
      "Epoch : 32 / 100\n",
      "Time to complete 32 is 0:00:13.801597\n",
      "Learning rate: 0.00014757395258967662\n",
      "Train Loss:  0.2312\n",
      "Valid Loss:  0.2292\n",
      "\n",
      "Epoch 00033: reducing learning rate of group 0 to 1.1806e-04.\n",
      "Early stoping counter: 4 out of 10\n",
      "Epoch : 33 / 100\n",
      "Time to complete 33 is 0:00:13.881376\n",
      "Learning rate: 0.0001180591620717413\n",
      "Train Loss:  0.2316\n",
      "Valid Loss:  0.2295\n",
      "\n",
      "Epoch 00034: reducing learning rate of group 0 to 9.4447e-05.\n",
      "Early stoping counter: 5 out of 10\n",
      "Epoch : 34 / 100\n",
      "Time to complete 34 is 0:00:13.875468\n",
      "Learning rate: 9.444732965739304e-05\n",
      "Train Loss:  0.2306\n",
      "Valid Loss:  0.2290\n",
      "\n",
      "Validation loss has decreased (0.229010 --> 0.228914). Saving model...\n",
      "Epoch : 35 / 100\n",
      "Time to complete 35 is 0:00:13.849398\n",
      "Learning rate: 9.444732965739304e-05\n",
      "Train Loss:  0.2308\n",
      "Valid Loss:  0.2289\n",
      "\n",
      "Epoch 00036: reducing learning rate of group 0 to 7.5558e-05.\n",
      "Early stoping counter: 1 out of 10\n",
      "Epoch : 36 / 100\n",
      "Time to complete 36 is 0:00:14.502737\n",
      "Learning rate: 7.555786372591443e-05\n",
      "Train Loss:  0.2308\n",
      "Valid Loss:  0.2293\n",
      "\n",
      "Validation loss has decreased (0.228914 --> 0.228730). Saving model...\n",
      "Epoch : 37 / 100\n",
      "Time to complete 37 is 0:00:13.992829\n",
      "Learning rate: 7.555786372591443e-05\n",
      "Train Loss:  0.2314\n",
      "Valid Loss:  0.2287\n",
      "\n",
      "Epoch 00038: reducing learning rate of group 0 to 6.0446e-05.\n",
      "Early stoping counter: 1 out of 10\n",
      "Epoch : 38 / 100\n",
      "Time to complete 38 is 0:00:14.365666\n",
      "Learning rate: 6.044629098073155e-05\n",
      "Train Loss:  0.2313\n",
      "Valid Loss:  0.2291\n",
      "\n",
      "Epoch 00039: reducing learning rate of group 0 to 4.8357e-05.\n",
      "Early stoping counter: 2 out of 10\n",
      "Epoch : 39 / 100\n",
      "Time to complete 39 is 0:00:13.943605\n",
      "Learning rate: 4.8357032784585246e-05\n",
      "Train Loss:  0.2310\n",
      "Valid Loss:  0.2289\n",
      "\n",
      "Epoch 00040: reducing learning rate of group 0 to 3.8686e-05.\n",
      "Early stoping counter: 3 out of 10\n",
      "Epoch : 40 / 100\n",
      "Time to complete 40 is 0:00:13.826404\n",
      "Learning rate: 3.86856262276682e-05\n",
      "Train Loss:  0.2313\n",
      "Valid Loss:  0.2288\n",
      "\n",
      "Epoch 00041: reducing learning rate of group 0 to 3.0949e-05.\n",
      "Early stoping counter: 4 out of 10\n",
      "Epoch : 41 / 100\n",
      "Time to complete 41 is 0:00:13.847337\n",
      "Learning rate: 3.094850098213456e-05\n",
      "Train Loss:  0.2307\n",
      "Valid Loss:  0.2288\n",
      "\n",
      "Epoch 00042: reducing learning rate of group 0 to 2.4759e-05.\n",
      "Early stoping counter: 5 out of 10\n",
      "Epoch : 42 / 100\n",
      "Time to complete 42 is 0:00:14.048912\n",
      "Learning rate: 2.4758800785707648e-05\n",
      "Train Loss:  0.2310\n",
      "Valid Loss:  0.2289\n",
      "\n",
      "Epoch 00043: reducing learning rate of group 0 to 1.9807e-05.\n",
      "Early stoping counter: 6 out of 10\n",
      "Epoch : 43 / 100\n",
      "Time to complete 43 is 0:00:13.776960\n",
      "Learning rate: 1.980704062856612e-05\n",
      "Train Loss:  0.2310\n",
      "Valid Loss:  0.2289\n",
      "\n",
      "Epoch 00044: reducing learning rate of group 0 to 1.5846e-05.\n",
      "Early stoping counter: 7 out of 10\n",
      "Epoch : 44 / 100\n",
      "Time to complete 44 is 0:00:13.827762\n",
      "Learning rate: 1.5845632502852897e-05\n",
      "Train Loss:  0.2306\n",
      "Valid Loss:  0.2289\n",
      "\n",
      "Epoch 00045: reducing learning rate of group 0 to 1.2677e-05.\n",
      "Early stoping counter: 8 out of 10\n",
      "Epoch : 45 / 100\n",
      "Time to complete 45 is 0:00:13.881861\n",
      "Learning rate: 1.2676506002282318e-05\n",
      "Train Loss:  0.2307\n",
      "Valid Loss:  0.2289\n",
      "\n",
      "Epoch 00046: reducing learning rate of group 0 to 1.0141e-05.\n",
      "Early stoping counter: 9 out of 10\n",
      "Epoch : 46 / 100\n",
      "Time to complete 46 is 0:00:13.919990\n",
      "Learning rate: 1.0141204801825855e-05\n",
      "Train Loss:  0.2310\n",
      "Valid Loss:  0.2289\n",
      "\n",
      "Epoch 00047: reducing learning rate of group 0 to 8.1130e-06.\n",
      "Early stoping counter: 10 out of 10\n",
      "Epoch : 47 / 100\n",
      "Time to complete 47 is 0:00:13.817239\n",
      "Learning rate: 8.112963841460684e-06\n",
      "Train Loss:  0.2304\n",
      "Valid Loss:  0.2289\n",
      "\n",
      "Epoch 00048: reducing learning rate of group 0 to 6.4904e-06.\n",
      "Early stoping counter: 11 out of 10\n",
      "Early Stopping\n"
     ]
    }
   ],
   "source": [
    "example_ct_train, batch_ct_train, example_ct_valid, batch_ct_valid = 0, 0, 0, 0\n",
    "train_loss_history, valid_loss_history = train_loop(train_loader,\n",
    "                                                    valid_loader, \n",
    "                                                    model_hw6_part_b_task5, \n",
    "                                                    loss_function, \n",
    "                                                    optimizer, \n",
    "                                                    wandb.config.EPOCHS, \n",
    "                                                    device,\n",
    "                                                    wandb.config.PATIENCE, \n",
    "                                                    wandb.config.EARLY_STOPPING,\n",
    "                                                    wandb.config.FILE_MODEL, \n",
    "                                                    wandb.config.SAVE_BEST_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1g-619j3CyQE"
   },
   "outputs": [],
   "source": [
    "def get_pred(data_loader, model):\n",
    "  \"\"\" \n",
    "  Function to get predictions for a given test set and calculate accuracy.\n",
    "  Input: Iterator to the test set.\n",
    "  Output: Prections and Accuracy for test set.\n",
    "  \"\"\"\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    # Array to store predicted labels\n",
    "    predictions = torch.Tensor()\n",
    "    predictions = predictions.to(device)\n",
    "    \n",
    "    outputs = torch.Tensor()\n",
    "    outputs = outputs.to(device)\n",
    "\n",
    "    # Array to store actual labels\n",
    "    y = torch.Tensor()\n",
    "    y = y.to(device)\n",
    "    # Iterate over batches from test set\n",
    "    for text, targets, offsets in data_loader:\n",
    "      \n",
    "      # move inputs and outputs to GPUs\n",
    "      text = text.to(device)\n",
    "      targets = targets.to(device)\n",
    "      offsets = offsets.to(device)\n",
    "      \n",
    "      # Calculated the predicted labels\n",
    "      output = model(text, offsets)\n",
    "      predicted_y = output.clone()\n",
    "\n",
    "      # Update teh output \n",
    "      predicted_y[predicted_y>0] = 1\n",
    "      predicted_y[predicted_y<=0] =0\n",
    "\n",
    "      # Add the predicted labels to the array\n",
    "      predictions = torch.cat((predictions, predicted_y)) \n",
    "    \n",
    "      outputs = torch.cat((outputs, output)) \n",
    "\n",
    "      # Add the actual labels to the array\n",
    "      y = torch.cat((y, targets)) \n",
    "\n",
    "  # Return array containing predictions and accuracy\n",
    "  return y, predictions\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1050,
     "status": "ok",
     "timestamp": 1651384804774,
     "user": {
      "displayName": "Vikash Kumar",
      "userId": "09277849211533188513"
     },
     "user_tz": 300
    },
    "id": "--34m2D-Ji2B",
    "outputId": "22a25e3b-b2a6-417c-9a4d-c969784d63d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_nn =MLPCustom(wandb.config.VOCAB_SIZE, \n",
    "                                    wandb.config.HIDDEN_SIZES_LIST, \n",
    "                                    wandb.config.DPROBS_LIST, \n",
    "                                    wandb.config.BATCHNORM_BINARY, \n",
    "                                    wandb.config.OUTPUT_DIM, \n",
    "                                    non_linearity, pretrained_weights_tensor)\n",
    "model_nn.to(device)\n",
    "model_nn.load_state_dict(torch.load(wandb.config.FILE_MODEL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 92,
     "status": "ok",
     "timestamp": 1651384808193,
     "user": {
      "displayName": "Vikash Kumar",
      "userId": "09277849211533188513"
     },
     "user_tz": 300
    },
    "id": "_pyBYrRHKFkJ",
    "outputId": "3ee7c4e3-cc7d-407f-f6b7-757c9b68da01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/Datasets_Models/Models/overfit_exp1.pt\n"
     ]
    }
   ],
   "source": [
    "print(wandb.config.FILE_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_cnkM2LKKHyJ"
   },
   "outputs": [],
   "source": [
    "# Get the prediction and labels\n",
    "y_train,  y_predicted_train = get_pred(train_loader, model_nn)\n",
    "y_valid, y_predicted_valid = get_pred(valid_loader, model_nn)\n",
    "y_test,  y_predicted_test  = get_pred(test_loader, model_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o2649DnEKJte"
   },
   "outputs": [],
   "source": [
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pqE8yUbJKLSW"
   },
   "outputs": [],
   "source": [
    "from torchmetrics import F1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SGwVL1vGKVNG"
   },
   "outputs": [],
   "source": [
    "f1score  = F1Score(num_classes=10, mdmc_average= 'global').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CeThQZyfKYHc"
   },
   "outputs": [],
   "source": [
    "train_f1_score = f1score( y_predicted_train, y_train.long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 112,
     "status": "ok",
     "timestamp": 1651384961585,
     "user": {
      "displayName": "Vikash Kumar",
      "userId": "09277849211533188513"
     },
     "user_tz": 300
    },
    "id": "AkCf0Wv8KZdX",
    "outputId": "b6f3fed9-4762-41f9-d67d-45756e11ced1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7578, device='cuda:0')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jan3fPbbKamA"
   },
   "outputs": [],
   "source": [
    "# convert these to numpy array\n",
    "y_train, y_predicted_train  = y_train.cpu().numpy(), y_predicted_train.cpu().numpy() \n",
    "y_valid, y_predicted_valid  = y_valid.cpu().numpy(), y_predicted_valid.cpu().numpy() \n",
    "y_test, y_predicted_test  = y_test.cpu().numpy(), y_predicted_test.cpu().numpy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "85pY-MXDKb4S"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "81yQPpuOKdEO"
   },
   "outputs": [],
   "source": [
    "f1_score_train = f1_score(y_train, y_predicted_train, average = 'micro')\n",
    "f1_score_valid = f1_score(y_valid, y_predicted_valid, average = 'micro')\n",
    "f1_score_test = f1_score(y_test, y_predicted_test, average = 'micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 110,
     "status": "ok",
     "timestamp": 1651384968946,
     "user": {
      "displayName": "Vikash Kumar",
      "userId": "09277849211533188513"
     },
     "user_tz": 300
    },
    "id": "p3aOohc7KeH8",
    "outputId": "b7eb28c4-bb4e-4922-9aa8-fbdea317036d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score_train 0.7577838362367728\n",
      "f1_score_valid 0.7583372934895033\n",
      "f1_score_test 0.7520747179790137\n"
     ]
    }
   ],
   "source": [
    "# Print Accuracy based on saved Model\n",
    "print('f1_score_train', f1_score_train)\n",
    "print('f1_score_valid', f1_score_valid)\n",
    "print('f1_score_test', f1_score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d7ktkaMLKfQg"
   },
   "outputs": [],
   "source": [
    "wandb.log({'Train f1 score': f1_score_train})\n",
    "wandb.log({'Valid f1 score': f1_score_valid}) \n",
    "wandb.log({'Test f1 score': f1_score_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330,
     "referenced_widgets": [
      "d6a05f198ac74623a85ddced18d70229",
      "e25178d807eb4bad89ba3600bec18cd6",
      "d1245e60662242dda4aec0834e39718b",
      "192ba0c3aea546c1bc018a27822caea8",
      "0600eb9b5986488aab39131487cb247a",
      "f06c2a6501864e8ab5810ca8f9ce8659",
      "a8342fd3d8484b56b55b64f1741b1a06",
      "82e6f2c8e4994edf844d91b2b51ca0c5"
     ]
    },
    "executionInfo": {
     "elapsed": 4906,
     "status": "ok",
     "timestamp": 1651384978687,
     "user": {
      "displayName": "Vikash Kumar",
      "userId": "09277849211533188513"
     },
     "user_tz": 300
    },
    "id": "oRLh5zCmKgiy",
    "outputId": "bccf4a0b-db0f-4eb4-dd16-546b0ca499b9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6a05f198ac74623a85ddced18d70229",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test f1 score</td><td>▁</td></tr><tr><td>Train Batch Loss  :</td><td>▇▆▇▅▆▄▆▇█▆▇▇▄▆▅▄▃▃▄▂▅▇▄▄▁▃▁▄▁▄▃▃▄▃▄▃▂▅▄▂</td></tr><tr><td>Train epoch Loss :</td><td>█▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train f1 score</td><td>▁</td></tr><tr><td>Valid Batch Loss  :</td><td>▇▇▄▃▄▂▆▆▆█▅▃▅▆▆▃▆▅▅▄▅▄▃▅▂▄▄▄▄▃▅▁▃▄▅▂▃▅▄█</td></tr><tr><td>Valid epoch Loss :</td><td>█▆▇▅▇▃▅▂▃▄▆▄▂▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Valid f1 score</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test f1 score</td><td>0.75207</td></tr><tr><td>Train Batch Loss  :</td><td>0.21306</td></tr><tr><td>Train epoch Loss :</td><td>0.23036</td></tr><tr><td>Train f1 score</td><td>0.75778</td></tr><tr><td>Valid Batch Loss  :</td><td>0.26704</td></tr><tr><td>Valid epoch Loss :</td><td>0.22885</td></tr><tr><td>Valid f1 score</td><td>0.75834</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">exp_1</strong>: <a href=\"https://wandb.ai/vikashk/hw6_part_b_full_task5/runs/5h5vbxra\" target=\"_blank\">https://wandb.ai/vikashk/hw6_part_b_full_task5/runs/5h5vbxra</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220501_054405-5h5vbxra/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OCgu-XLhKhjc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyO2wyMDzCkLHTPk2RSN8Au3",
   "collapsed_sections": [],
   "name": "Stackoverflow_Multilabel_Tagging_PreTrained_Embedding_Neural_Network.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0600eb9b5986488aab39131487cb247a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0cb2c24c742746eda4069d5e326749b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "192ba0c3aea546c1bc018a27822caea8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "276c5c617a1a48088f67054c5fabebde": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4a5e8c5b38a8467fae762fbc6cbdb4e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5310ec8231004042b2853697aed2248e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6a21d846bfdd4c40bbd82789038af82d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a95dcb6192214736ac100bb349923835",
       "IPY_MODEL_e42ce56a290442c1bcf486514416fb2e"
      ],
      "layout": "IPY_MODEL_276c5c617a1a48088f67054c5fabebde"
     }
    },
    "82e6f2c8e4994edf844d91b2b51ca0c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a8342fd3d8484b56b55b64f1741b1a06": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a95dcb6192214736ac100bb349923835": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4a5e8c5b38a8467fae762fbc6cbdb4e0",
      "placeholder": "​",
      "style": "IPY_MODEL_5310ec8231004042b2853697aed2248e",
      "value": "0.009 MB of 0.009 MB uploaded (0.000 MB deduped)\r"
     }
    },
    "d1245e60662242dda4aec0834e39718b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a8342fd3d8484b56b55b64f1741b1a06",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_82e6f2c8e4994edf844d91b2b51ca0c5",
      "value": 1
     }
    },
    "d6a05f198ac74623a85ddced18d70229": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e25178d807eb4bad89ba3600bec18cd6",
       "IPY_MODEL_d1245e60662242dda4aec0834e39718b"
      ],
      "layout": "IPY_MODEL_192ba0c3aea546c1bc018a27822caea8"
     }
    },
    "e25178d807eb4bad89ba3600bec18cd6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0600eb9b5986488aab39131487cb247a",
      "placeholder": "​",
      "style": "IPY_MODEL_f06c2a6501864e8ab5810ca8f9ce8659",
      "value": "0.037 MB of 0.037 MB uploaded (0.000 MB deduped)\r"
     }
    },
    "e42ce56a290442c1bcf486514416fb2e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f7fabda30572452cae2aeee06afb57d1",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0cb2c24c742746eda4069d5e326749b7",
      "value": 1
     }
    },
    "f06c2a6501864e8ab5810ca8f9ce8659": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f7fabda30572452cae2aeee06afb57d1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
